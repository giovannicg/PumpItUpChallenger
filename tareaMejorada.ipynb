{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.cluster import KMeans\n",
    "from geopy.distance import geodesic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DateFeaturesTransformer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Extrae características de fecha y calcula la edad del punto de agua.\n",
    "    Se encarga de transformar 'date_recorded' y calcular 'waterpoint_age' a partir de 'construction_year'.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.waterpoint_age_median = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        X = X.copy()\n",
    "        X[\"date_recorded\"] = pd.to_datetime(X[\"date_recorded\"])\n",
    "        X[\"year_recorded\"] = X[\"date_recorded\"].dt.year\n",
    "        X[\"month_recorded\"] = X[\"date_recorded\"].dt.month\n",
    "        X[\"day_recorded\"] = X[\"date_recorded\"].dt.day\n",
    "        X[\"waterpoint_age\"] = X[\"year_recorded\"] - X[\"construction_year\"]\n",
    "        # Calcula la mediana para imputar cuando construction_year==0\n",
    "        self.waterpoint_age_median = X.loc[X[\"construction_year\"] != 0, \"waterpoint_age\"].median()\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        X[\"date_recorded\"] = pd.to_datetime(X[\"date_recorded\"])\n",
    "        X[\"year_recorded\"] = X[\"date_recorded\"].dt.year\n",
    "        X[\"month_recorded\"] = X[\"date_recorded\"].dt.month\n",
    "        X[\"day_recorded\"] = X[\"date_recorded\"].dt.day\n",
    "        X[\"waterpoint_age\"] = X[\"year_recorded\"] - X[\"construction_year\"]\n",
    "        X.loc[X[\"construction_year\"] == 0, \"waterpoint_age\"] = self.waterpoint_age_median\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LocationClusterTransformer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Crea un cluster de ubicación usando las columnas 'longitude' y 'latitude'.\n",
    "    \"\"\"\n",
    "    def __init__(self, n_clusters=10, random_state=42):\n",
    "        self.n_clusters = n_clusters\n",
    "        self.random_state = random_state\n",
    "        self.kmeans = None\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        self.kmeans = KMeans(n_clusters=self.n_clusters, random_state=self.random_state, n_init=10)\n",
    "        self.kmeans.fit(X[[\"longitude\", \"latitude\"]])\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        X[\"location_cluster\"] = self.kmeans.predict(X[[\"longitude\", \"latitude\"]])\n",
    "        return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegionDistanceTransformer(BaseEstimator, TransformerMixin):\n",
    "    \"\"\"\n",
    "    Calcula la distancia entre la ubicación del punto y el centro (mediana) de la región.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        self.region_centers = {}\n",
    "\n",
    "    def fit(self, X, y=None):\n",
    "        # Calcula el centro (mediana) de cada región\n",
    "        self.region_centers = X.groupby(\"region\")[[\"latitude\", \"longitude\"]].median().to_dict('index')\n",
    "        return self\n",
    "\n",
    "    def transform(self, X):\n",
    "        X = X.copy()\n",
    "        def calc_distance(row):\n",
    "            region = row[\"region\"]\n",
    "            if region in self.region_centers:\n",
    "                center = self.region_centers[region]\n",
    "                return geodesic((row[\"latitude\"], row[\"longitude\"]),\n",
    "                                (center[\"latitude\"], center[\"longitude\"])).km\n",
    "            else:\n",
    "                return np.nan\n",
    "        X[\"distance_to_region_center\"] = X.apply(calc_distance, axis=1)\n",
    "        return X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga los datos\n",
    "df_1 = pd.read_csv('data1.csv')\n",
    "df_2 = pd.read_csv('data2.csv')\n",
    "df_target = pd.read_csv('objetivo.csv')\n",
    "\n",
    "# Une los DataFrames de entrenamiento y combina con el target\n",
    "df = pd.concat([df_1, df_2], axis=0)\n",
    "df_final = pd.merge(df, df_target, on=\"id\")\n",
    "\n",
    "# Separa la variable objetivo\n",
    "y = df_final['status_group']\n",
    "X = df_final.drop(columns=['status_group'])\n",
    "\n",
    "#  Elimina columnas que no vayas a usar\n",
    "columns_to_drop = ['recorded_by']\n",
    "X = X.drop(columns=columns_to_drop)\n",
    "\n",
    "# Define los nombres de las columnas según el procesamiento:\n",
    "# Aquí se asume que las variables numéricas y categóricas son aquellas que usarás en el modelo.\n",
    "numeric_features = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical_features = X.select_dtypes(include=['object']).columns.tolist()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline para el preprocesamiento de datos\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        # Transformación para variables numéricas: imputar y escalar\n",
    "        ('num', Pipeline(steps=[\n",
    "            ('imputer', SimpleImputer(strategy=\"median\")),\n",
    "            ('scaler', MinMaxScaler())\n",
    "        ]), numeric_features),\n",
    "        # Transformación para variables categóricas: imputar y aplicar OneHotEncoding\n",
    "        ('cat', Pipeline(steps=[\n",
    "            ('imputer', SimpleImputer(strategy=\"most_frequent\")),\n",
    "            ('onehot', OneHotEncoder(drop='first', handle_unknown='ignore'))\n",
    "        ]), categorical_features)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pipeline completo que encadena los pasos de feature engineering y el modelo\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('date_features', DateFeaturesTransformer()),\n",
    "    ('location_cluster', LocationClusterTransformer(n_clusters=10)),\n",
    "    ('region_distance', RegionDistanceTransformer()),\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('classifier', RandomForestClassifier(n_estimators=100, random_state=42))\n",
    "])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/giovannicapote/Documents/Master/Data Science/Tarea/.venv/lib/python3.13/site-packages/sklearn/preprocessing/_encoders.py:246: UserWarning: Found unknown categories in columns [0, 1, 2, 3, 5, 8, 11] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.802300785634119\n",
      "Classification Report:\n",
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             functional       0.80      0.89      0.84      9724\n",
      "functional needs repair       0.58      0.33      0.42      1293\n",
      "         non functional       0.83      0.77      0.80      6803\n",
      "\n",
      "               accuracy                           0.80     17820\n",
      "              macro avg       0.74      0.66      0.69     17820\n",
      "           weighted avg       0.80      0.80      0.80     17820\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/giovannicapote/Documents/Master/Data Science/Tarea/.venv/lib/python3.13/site-packages/sklearn/preprocessing/_encoders.py:246: UserWarning: Found unknown categories in columns [0, 1, 2, 3, 5, 8, 11] during transform. These unknown categories will be encoded as all zeros\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Primeras 5 predicciones:\n",
      "      id    status_group\n",
      "0  50785      functional\n",
      "1  51630      functional\n",
      "2  17168      functional\n",
      "3  45559  non functional\n",
      "4  49871      functional\n"
     ]
    }
   ],
   "source": [
    "# Dividir los datos de entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Entrenar el pipeline\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Evaluar el modelo en el set de prueba\n",
    "y_pred = pipeline.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# ======================\n",
    "# PREDICCIÓN SOBRE NUEVOS DATOS\n",
    "# ======================\n",
    "\n",
    "# Cargar y procesar el DataFrame de predicción\n",
    "prediciton_df = pd.read_csv('predicion.csv')\n",
    "\n",
    "prediciton_df = prediciton_df.drop(columns=columns_to_drop)\n",
    "\n",
    "# Aplica el pipeline entrenado (se aplicarán todos los pasos de transformación de forma consistente)\n",
    "predictions = pipeline.predict(prediciton_df)\n",
    "\n",
    "# Agrega las predicciones y guarda el resultado\n",
    "prediciton_df[\"status_group\"] = predictions\n",
    "final_result = prediciton_df[['id', 'status_group']]\n",
    "final_result.to_csv('resultados_predicciones.csv', index=False)\n",
    "print(\"\\nPrimeras 5 predicciones:\")\n",
    "print(prediciton_df[['id', 'status_group']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importancia de las 10 características principales:\n",
      "                                feature  importance\n",
      "3                        num__longitude    0.037327\n",
      "4                         num__latitude    0.037236\n",
      "0                               num__id    0.030996\n",
      "2                       num__gps_height    0.024158\n",
      "9                num__construction_year    0.019624\n",
      "8                       num__population    0.017929\n",
      "51827              cat__quantity_enough    0.016070\n",
      "51831        cat__quantity_group_enough    0.015435\n",
      "51862  cat__waterpoint_type_group_other    0.010482\n",
      "51784  cat__extraction_type_class_other    0.010194\n"
     ]
    }
   ],
   "source": [
    "# Extraer los nombres de las features del preprocesador\n",
    "feature_names = pipeline.named_steps['preprocessor'].get_feature_names_out()\n",
    "\n",
    "# Obtener las importancias del clasificador\n",
    "importances = pipeline.named_steps['classifier'].feature_importances_\n",
    "\n",
    "# Crear un DataFrame para visualizar la importancia de cada feature\n",
    "feat_importances = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'importance': importances\n",
    "}).sort_values(by='importance', ascending=False)\n",
    "\n",
    "print(\"Importancia de las 10 características principales:\")\n",
    "print(feat_importances.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01minspection\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m permutation_importance\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Calcular la Permutation Importance usando el pipeline completo y el set de prueba\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m result = \u001b[43mpermutation_importance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpipeline\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_repeats\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m30\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m42\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[38;5;66;03m# Obtener las importancias medias\u001b[39;00m\n\u001b[32m      7\u001b[39m perm_importances = pd.DataFrame({\n\u001b[32m      8\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mfeature\u001b[39m\u001b[33m'\u001b[39m: feature_names,\n\u001b[32m      9\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mimportance_mean\u001b[39m\u001b[33m'\u001b[39m: result.importances_mean,\n\u001b[32m     10\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mimportance_std\u001b[39m\u001b[33m'\u001b[39m: result.importances_std\n\u001b[32m     11\u001b[39m }).sort_values(by=\u001b[33m'\u001b[39m\u001b[33mimportance_mean\u001b[39m\u001b[33m'\u001b[39m, ascending=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Master/Data Science/Tarea/.venv/lib/python3.13/site-packages/sklearn/utils/_param_validation.py:216\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    210\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    211\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    212\u001b[39m         skip_parameter_validation=(\n\u001b[32m    213\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    214\u001b[39m         )\n\u001b[32m    215\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m216\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    217\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    218\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    219\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    222\u001b[39m     msg = re.sub(\n\u001b[32m    223\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    224\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    225\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    226\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Master/Data Science/Tarea/.venv/lib/python3.13/site-packages/sklearn/inspection/_permutation_importance.py:287\u001b[39m, in \u001b[36mpermutation_importance\u001b[39m\u001b[34m(estimator, X, y, scoring, n_repeats, n_jobs, random_state, sample_weight, max_samples)\u001b[39m\n\u001b[32m    284\u001b[39m scorer = check_scoring(estimator, scoring=scoring)\n\u001b[32m    285\u001b[39m baseline_score = _weights_scorer(scorer, estimator, X, y, sample_weight)\n\u001b[32m--> \u001b[39m\u001b[32m287\u001b[39m scores = \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    288\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_calculate_permutation_scores\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    289\u001b[39m \u001b[43m        \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    290\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    291\u001b[39m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    292\u001b[39m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    293\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcol_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    294\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrandom_seed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    295\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_repeats\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    296\u001b[39m \u001b[43m        \u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    297\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_samples\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    298\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    299\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mcol_idx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m.\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    300\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    302\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(baseline_score, \u001b[38;5;28mdict\u001b[39m):\n\u001b[32m    303\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[32m    304\u001b[39m         name: _create_importances_bunch(\n\u001b[32m    305\u001b[39m             baseline_score[name],\n\u001b[32m   (...)\u001b[39m\u001b[32m    309\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m baseline_score\n\u001b[32m    310\u001b[39m     }\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Master/Data Science/Tarea/.venv/lib/python3.13/site-packages/sklearn/utils/parallel.py:77\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m     72\u001b[39m config = get_config()\n\u001b[32m     73\u001b[39m iterable_with_config = (\n\u001b[32m     74\u001b[39m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[32m     76\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Master/Data Science/Tarea/.venv/lib/python3.13/site-packages/joblib/parallel.py:1918\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1916\u001b[39m     output = \u001b[38;5;28mself\u001b[39m._get_sequential_output(iterable)\n\u001b[32m   1917\u001b[39m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m1918\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1920\u001b[39m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[32m   1921\u001b[39m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[32m   1922\u001b[39m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[32m   1923\u001b[39m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[32m   1924\u001b[39m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[32m   1925\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._lock:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Master/Data Science/Tarea/.venv/lib/python3.13/site-packages/joblib/parallel.py:1847\u001b[39m, in \u001b[36mParallel._get_sequential_output\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   1845\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_batches += \u001b[32m1\u001b[39m\n\u001b[32m   1846\u001b[39m \u001b[38;5;28mself\u001b[39m.n_dispatched_tasks += \u001b[32m1\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1847\u001b[39m res = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1848\u001b[39m \u001b[38;5;28mself\u001b[39m.n_completed_tasks += \u001b[32m1\u001b[39m\n\u001b[32m   1849\u001b[39m \u001b[38;5;28mself\u001b[39m.print_progress()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Master/Data Science/Tarea/.venv/lib/python3.13/site-packages/sklearn/utils/parallel.py:139\u001b[39m, in \u001b[36m_FuncWrapper.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    137\u001b[39m     config = {}\n\u001b[32m    138\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m config_context(**config):\n\u001b[32m--> \u001b[39m\u001b[32m139\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Master/Data Science/Tarea/.venv/lib/python3.13/site-packages/sklearn/inspection/_permutation_importance.py:75\u001b[39m, in \u001b[36m_calculate_permutation_scores\u001b[39m\u001b[34m(estimator, X, y, sample_weight, col_idx, random_state, n_repeats, scorer, max_samples)\u001b[39m\n\u001b[32m     73\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     74\u001b[39m         X_permuted[:, col_idx] = X_permuted[shuffling_idx, col_idx]\n\u001b[32m---> \u001b[39m\u001b[32m75\u001b[39m     scores.append(\u001b[43m_weights_scorer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscorer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_permuted\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m     77\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(scores[\u001b[32m0\u001b[39m], \u001b[38;5;28mdict\u001b[39m):\n\u001b[32m     78\u001b[39m     scores = _aggregate_score_dicts(scores)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Master/Data Science/Tarea/.venv/lib/python3.13/site-packages/sklearn/inspection/_permutation_importance.py:28\u001b[39m, in \u001b[36m_weights_scorer\u001b[39m\u001b[34m(scorer, estimator, X, y, sample_weight)\u001b[39m\n\u001b[32m     26\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m     27\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m scorer(estimator, X, y, sample_weight=sample_weight)\n\u001b[32m---> \u001b[39m\u001b[32m28\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mscorer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Master/Data Science/Tarea/.venv/lib/python3.13/site-packages/sklearn/metrics/_scorer.py:472\u001b[39m, in \u001b[36m_PassthroughScorer.__call__\u001b[39m\u001b[34m(self, estimator, *args, **kwargs)\u001b[39m\n\u001b[32m    470\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, estimator, *args, **kwargs):\n\u001b[32m    471\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Method that wraps estimator.score\"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m472\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mestimator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mscore\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Master/Data Science/Tarea/.venv/lib/python3.13/site-packages/sklearn/pipeline.py:1195\u001b[39m, in \u001b[36mPipeline.score\u001b[39m\u001b[34m(self, X, y, sample_weight, **params)\u001b[39m\n\u001b[32m   1193\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m _routing_enabled():\n\u001b[32m   1194\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m _, name, transform \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._iter(with_final=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m-> \u001b[39m\u001b[32m1195\u001b[39m         Xt = \u001b[43mtransform\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mXt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1196\u001b[39m     score_params = {}\n\u001b[32m   1197\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m sample_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Master/Data Science/Tarea/.venv/lib/python3.13/site-packages/sklearn/utils/_set_output.py:319\u001b[39m, in \u001b[36m_wrap_method_output.<locals>.wrapped\u001b[39m\u001b[34m(self, X, *args, **kwargs)\u001b[39m\n\u001b[32m    317\u001b[39m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[32m    318\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, *args, **kwargs):\n\u001b[32m--> \u001b[39m\u001b[32m319\u001b[39m     data_to_wrap = \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    320\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[32m    321\u001b[39m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[32m    322\u001b[39m         return_tuple = (\n\u001b[32m    323\u001b[39m             _wrap_data_with_container(method, data_to_wrap[\u001b[32m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[32m    324\u001b[39m             *data_to_wrap[\u001b[32m1\u001b[39m:],\n\u001b[32m    325\u001b[39m         )\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 23\u001b[39m, in \u001b[36mRegionDistanceTransformer.transform\u001b[39m\u001b[34m(self, X)\u001b[39m\n\u001b[32m     21\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     22\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m np.nan\n\u001b[32m---> \u001b[39m\u001b[32m23\u001b[39m X[\u001b[33m\"\u001b[39m\u001b[33mdistance_to_region_center\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[43mX\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcalc_distance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m X\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Master/Data Science/Tarea/.venv/lib/python3.13/site-packages/pandas/core/frame.py:10374\u001b[39m, in \u001b[36mDataFrame.apply\u001b[39m\u001b[34m(self, func, axis, raw, result_type, args, by_row, engine, engine_kwargs, **kwargs)\u001b[39m\n\u001b[32m  10360\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcore\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mapply\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[32m  10362\u001b[39m op = frame_apply(\n\u001b[32m  10363\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m  10364\u001b[39m     func=func,\n\u001b[32m   (...)\u001b[39m\u001b[32m  10372\u001b[39m     kwargs=kwargs,\n\u001b[32m  10373\u001b[39m )\n\u001b[32m> \u001b[39m\u001b[32m10374\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m.__finalize__(\u001b[38;5;28mself\u001b[39m, method=\u001b[33m\"\u001b[39m\u001b[33mapply\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Master/Data Science/Tarea/.venv/lib/python3.13/site-packages/pandas/core/apply.py:916\u001b[39m, in \u001b[36mFrameApply.apply\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    913\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.raw:\n\u001b[32m    914\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.apply_raw(engine=\u001b[38;5;28mself\u001b[39m.engine, engine_kwargs=\u001b[38;5;28mself\u001b[39m.engine_kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m916\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Master/Data Science/Tarea/.venv/lib/python3.13/site-packages/pandas/core/apply.py:1063\u001b[39m, in \u001b[36mFrameApply.apply_standard\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1061\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m   1062\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.engine == \u001b[33m\"\u001b[39m\u001b[33mpython\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m1063\u001b[39m         results, res_index = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mapply_series_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1064\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1065\u001b[39m         results, res_index = \u001b[38;5;28mself\u001b[39m.apply_series_numba()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Master/Data Science/Tarea/.venv/lib/python3.13/site-packages/pandas/core/apply.py:1081\u001b[39m, in \u001b[36mFrameApply.apply_series_generator\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1078\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[33m\"\u001b[39m\u001b[33mmode.chained_assignment\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m   1079\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[32m   1080\u001b[39m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1081\u001b[39m         results[i] = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1082\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[32m   1083\u001b[39m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[32m   1084\u001b[39m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[32m   1085\u001b[39m             results[i] = results[i].copy(deep=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 19\u001b[39m, in \u001b[36mRegionDistanceTransformer.transform.<locals>.calc_distance\u001b[39m\u001b[34m(row)\u001b[39m\n\u001b[32m     17\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m region \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.region_centers:\n\u001b[32m     18\u001b[39m     center = \u001b[38;5;28mself\u001b[39m.region_centers[region]\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgeodesic\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlatitude\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlongitude\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m                    \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcenter\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlatitude\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcenter\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlongitude\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m.km\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     22\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m np.nan\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Master/Data Science/Tarea/.venv/lib/python3.13/site-packages/geopy/distance.py:540\u001b[39m, in \u001b[36mgeodesic.__init__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    538\u001b[39m \u001b[38;5;28mself\u001b[39m.set_ellipsoid(kwargs.pop(\u001b[33m'\u001b[39m\u001b[33mellipsoid\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mWGS-84\u001b[39m\u001b[33m'\u001b[39m))\n\u001b[32m    539\u001b[39m major, minor, f = \u001b[38;5;28mself\u001b[39m.ELLIPSOID\n\u001b[32m--> \u001b[39m\u001b[32m540\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Master/Data Science/Tarea/.venv/lib/python3.13/site-packages/geopy/distance.py:276\u001b[39m, in \u001b[36mDistance.__init__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    274\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) > \u001b[32m1\u001b[39m:\n\u001b[32m    275\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m a, b \u001b[38;5;129;01min\u001b[39;00m util.pairwise(args):\n\u001b[32m--> \u001b[39m\u001b[32m276\u001b[39m         kilometers += \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmeasure\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    278\u001b[39m kilometers += units.kilometers(**kwargs)\n\u001b[32m    279\u001b[39m \u001b[38;5;28mself\u001b[39m.__kilometers = kilometers\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Master/Data Science/Tarea/.venv/lib/python3.13/site-packages/geopy/distance.py:566\u001b[39m, in \u001b[36mgeodesic.measure\u001b[39m\u001b[34m(self, a, b)\u001b[39m\n\u001b[32m    561\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m.geod, Geodesic) \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    562\u001b[39m         \u001b[38;5;28mself\u001b[39m.geod.a == \u001b[38;5;28mself\u001b[39m.ELLIPSOID[\u001b[32m0\u001b[39m] \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[32m    563\u001b[39m         \u001b[38;5;28mself\u001b[39m.geod.f == \u001b[38;5;28mself\u001b[39m.ELLIPSOID[\u001b[32m2\u001b[39m]):\n\u001b[32m    564\u001b[39m     \u001b[38;5;28mself\u001b[39m.geod = Geodesic(\u001b[38;5;28mself\u001b[39m.ELLIPSOID[\u001b[32m0\u001b[39m], \u001b[38;5;28mself\u001b[39m.ELLIPSOID[\u001b[32m2\u001b[39m])\n\u001b[32m--> \u001b[39m\u001b[32m566\u001b[39m s12 = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgeod\u001b[49m\u001b[43m.\u001b[49m\u001b[43mInverse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlat1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlon1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlat2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlon2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    567\u001b[39m \u001b[43m                        \u001b[49m\u001b[43mGeodesic\u001b[49m\u001b[43m.\u001b[49m\u001b[43mDISTANCE\u001b[49m\u001b[43m)\u001b[49m[\u001b[33m'\u001b[39m\u001b[33ms12\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m    569\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m s12\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Master/Data Science/Tarea/.venv/lib/python3.13/site-packages/geographiclib/geodesic.py:1030\u001b[39m, in \u001b[36mGeodesic.Inverse\u001b[39m\u001b[34m(self, lat1, lon1, lat2, lon2, outmask)\u001b[39m\n\u001b[32m   1012\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mInverse\u001b[39m(\u001b[38;5;28mself\u001b[39m, lat1, lon1, lat2, lon2,\n\u001b[32m   1013\u001b[39m             outmask = GeodesicCapability.STANDARD):\n\u001b[32m   1014\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Solve the inverse geodesic problem\u001b[39;00m\n\u001b[32m   1015\u001b[39m \n\u001b[32m   1016\u001b[39m \u001b[33;03m  :param lat1: latitude of the first point in degrees\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1027\u001b[39m \n\u001b[32m   1028\u001b[39m \u001b[33;03m  \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1030\u001b[39m   a12, s12, salp1,calp1, salp2,calp2, m12, M12, M21, S12 = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_GenInverse\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1031\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlat1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlon1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlat2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlon2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutmask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1032\u001b[39m   outmask &= Geodesic.OUT_MASK\n\u001b[32m   1033\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m outmask & Geodesic.LONG_UNROLL:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Master/Data Science/Tarea/.venv/lib/python3.13/site-packages/geographiclib/geodesic.py:876\u001b[39m, in \u001b[36mGeodesic._GenInverse\u001b[39m\u001b[34m(self, lat1, lon1, lat2, lon2, outmask)\u001b[39m\n\u001b[32m    870\u001b[39m salp1b = Geodesic.tiny_; calp1b = -\u001b[32m1.0\u001b[39m\n\u001b[32m    872\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m numit < Geodesic.maxit2_:\n\u001b[32m    873\u001b[39m   \u001b[38;5;66;03m# the WGS84 test set: mean = 1.47, sd = 1.25, max = 16\u001b[39;00m\n\u001b[32m    874\u001b[39m   \u001b[38;5;66;03m# WGS84 and random input: mean = 2.85, sd = 0.60\u001b[39;00m\n\u001b[32m    875\u001b[39m   (v, salp2, calp2, sig12, ssig1, csig1, ssig2, csig2,\n\u001b[32m--> \u001b[39m\u001b[32m876\u001b[39m    eps, domg12, dv) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_Lambda12\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m     \u001b[49m\u001b[43msbet1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcbet1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdn1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msbet2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcbet2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdn2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m     \u001b[49m\u001b[43msalp1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcalp1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mslam12\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclam12\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumit\u001b[49m\u001b[43m \u001b[49m\u001b[43m<\u001b[49m\u001b[43m \u001b[49m\u001b[43mGeodesic\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmaxit1_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m     \u001b[49m\u001b[43mC1a\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mC2a\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mC3a\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m   \u001b[38;5;66;03m# Reversed test to allow escape with NaNs\u001b[39;00m\n\u001b[32m    881\u001b[39m   \u001b[38;5;28;01mif\u001b[39;00m tripb \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mabs\u001b[39m(v) >= (\u001b[32m8\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m tripn \u001b[38;5;28;01melse\u001b[39;00m \u001b[32m1\u001b[39m) * Geodesic.tol0_):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Master/Data Science/Tarea/.venv/lib/python3.13/site-packages/geographiclib/geodesic.py:683\u001b[39m, in \u001b[36mGeodesic._Lambda12\u001b[39m\u001b[34m(self, sbet1, cbet1, dn1, sbet2, cbet2, dn2, salp1, calp1, slam120, clam120, diffp, C1a, C2a, C3a)\u001b[39m\n\u001b[32m    680\u001b[39m \u001b[38;5;28mself\u001b[39m._C3f(eps, C3a)\n\u001b[32m    681\u001b[39m B312 = (Geodesic._SinCosSeries(\u001b[38;5;28;01mTrue\u001b[39;00m, ssig2, csig2, C3a) -\n\u001b[32m    682\u001b[39m         Geodesic._SinCosSeries(\u001b[38;5;28;01mTrue\u001b[39;00m, ssig1, csig1, C3a))\n\u001b[32m--> \u001b[39m\u001b[32m683\u001b[39m domg12 =  -\u001b[38;5;28mself\u001b[39m.f * \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_A3f\u001b[49m\u001b[43m(\u001b[49m\u001b[43meps\u001b[49m\u001b[43m)\u001b[49m * salp0 * (sig12 + B312)\n\u001b[32m    684\u001b[39m lam12 = eta + domg12\n\u001b[32m    686\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m diffp:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Master/Data Science/Tarea/.venv/lib/python3.13/site-packages/geographiclib/geodesic.py:403\u001b[39m, in \u001b[36mGeodesic._A3f\u001b[39m\u001b[34m(self, eps)\u001b[39m\n\u001b[32m    401\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Private: return A3\"\"\"\u001b[39;00m\n\u001b[32m    402\u001b[39m \u001b[38;5;66;03m# Evaluate A3\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m403\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mMath\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpolyval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mGeodesic\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnA3_\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_A3x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/Master/Data Science/Tarea/.venv/lib/python3.13/site-packages/geographiclib/geomath.py:68\u001b[39m, in \u001b[36mMath.polyval\u001b[39m\u001b[34m(N, p, s, x)\u001b[39m\n\u001b[32m     65\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Evaluate a polynomial.\"\"\"\u001b[39;00m\n\u001b[32m     67\u001b[39m y = \u001b[38;5;28mfloat\u001b[39m(\u001b[32m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m N < \u001b[32m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m p[s]) \u001b[38;5;66;03m# make sure the returned value is a float\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m68\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m N > \u001b[32m0\u001b[39m:\n\u001b[32m     69\u001b[39m   N -= \u001b[32m1\u001b[39m; s += \u001b[32m1\u001b[39m\n\u001b[32m     70\u001b[39m   y = y * x + p[s]\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "\n",
    "# Calcular la Permutation Importance usando el pipeline completo y el set de prueba\n",
    "result = permutation_importance(pipeline, X_test, y_test, n_repeats=30, random_state=42)\n",
    "\n",
    "# Obtener las importancias medias\n",
    "perm_importances = pd.DataFrame({\n",
    "    'feature': feature_names,\n",
    "    'importance_mean': result.importances_mean,\n",
    "    'importance_std': result.importances_std\n",
    "}).sort_values(by='importance_mean', ascending=False)\n",
    "\n",
    "print(\"Permutation Importance de las 10 características principales:\")\n",
    "print(perm_importances.head(10))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
